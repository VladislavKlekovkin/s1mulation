{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-cross-entropy-method.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPaBtN5mSBwXGTyPwNxpCMm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VladislavKlekovkin/s1mulation/blob/master/1_cross_entropy_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWpKIaphlWLn"
      },
      "source": [
        "You need to run this code from the google colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4Qz52sS6gvt",
        "outputId": "9bcebba9-c195-4ab7-a9af-5ebfade6cd9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "!git clone https://github.com/VladislavKlekovkin/s1mulation.git \n",
        "sys.path.append(os.path.join('./', 's1mulation'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 's1mulation'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 24 (delta 8), reused 10 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUqiFWDbgqLd"
      },
      "source": [
        "from environment import Space\n",
        "\n",
        "#import gym\n",
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 16\n",
        "PERCENTILE = 70"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoJkK3Mnw2oK"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, obs_size, hidden_size, n_actions):\n",
        "        super(Net, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(obs_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, n_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsnFERQSw5cF"
      },
      "source": [
        "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
        "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb2MiwFZw8eB"
      },
      "source": [
        "def iterate_batches(env, net, batch_size):\n",
        "    batch = []\n",
        "    episode_reward = 0.0\n",
        "    episode_steps = []\n",
        "    obs = env.reset()\n",
        "    sm = nn.Softmax(dim=1)\n",
        "    while True:\n",
        "        obs_v = torch.FloatTensor([obs])\n",
        "        act_probs_v = sm(net(obs_v))\n",
        "        act_probs = act_probs_v.data.numpy()[0]\n",
        "        action = np.random.choice(len(act_probs), p=act_probs)\n",
        "        next_obs, reward, is_done, _ = env.step(action)\n",
        "        episode_reward += reward\n",
        "        episode_steps.append(EpisodeStep(observation=obs, action=action))\n",
        "        if is_done:\n",
        "            batch.append(Episode(reward=episode_reward, steps=episode_steps))\n",
        "            episode_reward = 0.0\n",
        "            episode_steps = []\n",
        "            next_obs = env.reset()\n",
        "            if len(batch) == batch_size:\n",
        "                yield batch\n",
        "                batch = []\n",
        "        obs = next_obs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl5Y2y3Sw__x"
      },
      "source": [
        "def filter_batch(batch, percentile):\n",
        "    rewards = list(map(lambda s: s.reward, batch))\n",
        "    reward_bound = np.percentile(rewards, percentile)\n",
        "    reward_mean = float(np.mean(rewards))\n",
        "\n",
        "    train_obs = []\n",
        "    train_act = []\n",
        "    for example in batch:\n",
        "        if example.reward < reward_bound:\n",
        "            continue\n",
        "        train_obs.extend(map(lambda step: step.observation, example.steps))\n",
        "        train_act.extend(map(lambda step: step.action, example.steps))\n",
        "\n",
        "    train_obs_v = torch.FloatTensor(train_obs)\n",
        "    train_act_v = torch.LongTensor(train_act)\n",
        "    return train_obs_v, train_act_v, reward_bound, reward_mean"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSI_5le3lKmi",
        "outputId": "75813efc-29cc-44d7-82fd-4b32743d8d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Space()\n",
        "# env = gym.wrappers.Monitor(env, directory=\"mon\", force=True)\n",
        "obs_size = env.width * env.height\n",
        "n_actions = len(env.action_space)\n",
        "\n",
        "net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
        "objective = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params=net.parameters(), lr=0.01)\n",
        "writer = SummaryWriter(comment=\"-cartpole\")\n",
        "\n",
        "for iter_no, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):\n",
        "    obs_v, acts_v, reward_b, reward_m = filter_batch(batch, PERCENTILE)\n",
        "    optimizer.zero_grad()\n",
        "    action_scores_v = net(obs_v)\n",
        "    loss_v = objective(action_scores_v, acts_v)\n",
        "    loss_v.backward()\n",
        "    optimizer.step()\n",
        "    print(\"%d: loss=%.3f, reward_mean=%.1f, reward_bound=%.1f\" % (\n",
        "        iter_no, loss_v.item(), reward_m, reward_b))\n",
        "    writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
        "    writer.add_scalar(\"reward_bound\", reward_b, iter_no)\n",
        "    writer.add_scalar(\"reward_mean\", reward_m, iter_no)\n",
        "    if reward_m > 199:\n",
        "        print(\"Solved!\")\n",
        "        break\n",
        "writer.close()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evn initializing\n",
            "0: loss=1.386, reward_mean=1.0, reward_bound=1.0\n",
            "1: loss=1.386, reward_mean=1.0, reward_bound=1.0\n",
            "2: loss=1.383, reward_mean=1.0, reward_bound=1.0\n",
            "3: loss=1.382, reward_mean=1.0, reward_bound=1.0\n",
            "4: loss=1.375, reward_mean=1.0, reward_bound=1.0\n",
            "5: loss=1.371, reward_mean=1.0, reward_bound=1.0\n",
            "6: loss=1.361, reward_mean=1.0, reward_bound=1.0\n",
            "7: loss=1.362, reward_mean=1.0, reward_bound=1.0\n",
            "8: loss=1.350, reward_mean=1.0, reward_bound=1.0\n",
            "9: loss=1.358, reward_mean=1.0, reward_bound=1.0\n",
            "10: loss=1.358, reward_mean=1.0, reward_bound=1.0\n",
            "11: loss=1.349, reward_mean=1.0, reward_bound=1.0\n",
            "12: loss=1.353, reward_mean=1.0, reward_bound=1.0\n",
            "13: loss=1.361, reward_mean=1.0, reward_bound=1.0\n",
            "14: loss=1.358, reward_mean=1.0, reward_bound=1.0\n",
            "15: loss=1.360, reward_mean=1.0, reward_bound=1.0\n",
            "16: loss=1.352, reward_mean=1.0, reward_bound=1.0\n",
            "17: loss=1.359, reward_mean=1.0, reward_bound=1.0\n",
            "18: loss=1.353, reward_mean=1.0, reward_bound=1.0\n",
            "19: loss=1.357, reward_mean=1.0, reward_bound=1.0\n",
            "20: loss=1.358, reward_mean=1.0, reward_bound=1.0\n",
            "21: loss=1.364, reward_mean=1.0, reward_bound=1.0\n",
            "22: loss=1.358, reward_mean=1.0, reward_bound=1.0\n",
            "23: loss=1.353, reward_mean=1.0, reward_bound=1.0\n",
            "24: loss=1.359, reward_mean=1.0, reward_bound=1.0\n",
            "25: loss=1.350, reward_mean=1.0, reward_bound=1.0\n",
            "26: loss=1.349, reward_mean=1.0, reward_bound=1.0\n",
            "27: loss=1.350, reward_mean=1.0, reward_bound=1.0\n",
            "28: loss=1.354, reward_mean=1.0, reward_bound=1.0\n",
            "29: loss=1.351, reward_mean=1.0, reward_bound=1.0\n",
            "30: loss=1.347, reward_mean=1.0, reward_bound=1.0\n",
            "31: loss=1.344, reward_mean=1.0, reward_bound=1.0\n",
            "32: loss=1.340, reward_mean=1.0, reward_bound=1.0\n",
            "33: loss=1.329, reward_mean=1.0, reward_bound=1.0\n",
            "34: loss=1.352, reward_mean=1.0, reward_bound=1.0\n",
            "35: loss=1.340, reward_mean=1.0, reward_bound=1.0\n",
            "36: loss=1.351, reward_mean=1.0, reward_bound=1.0\n",
            "37: loss=1.342, reward_mean=1.0, reward_bound=1.0\n",
            "38: loss=1.342, reward_mean=1.0, reward_bound=1.0\n",
            "39: loss=1.349, reward_mean=1.0, reward_bound=1.0\n",
            "40: loss=1.336, reward_mean=1.0, reward_bound=1.0\n",
            "41: loss=1.351, reward_mean=1.0, reward_bound=1.0\n",
            "42: loss=1.345, reward_mean=1.0, reward_bound=1.0\n",
            "43: loss=1.355, reward_mean=1.0, reward_bound=1.0\n",
            "44: loss=1.355, reward_mean=1.0, reward_bound=1.0\n",
            "45: loss=1.360, reward_mean=1.0, reward_bound=1.0\n",
            "46: loss=1.347, reward_mean=1.0, reward_bound=1.0\n",
            "47: loss=1.347, reward_mean=1.0, reward_bound=1.0\n",
            "48: loss=1.360, reward_mean=1.0, reward_bound=1.0\n",
            "49: loss=1.356, reward_mean=1.0, reward_bound=1.0\n",
            "50: loss=1.350, reward_mean=1.0, reward_bound=1.0\n",
            "51: loss=1.340, reward_mean=1.0, reward_bound=1.0\n",
            "52: loss=1.322, reward_mean=1.0, reward_bound=1.0\n",
            "53: loss=1.332, reward_mean=1.0, reward_bound=1.0\n",
            "54: loss=1.336, reward_mean=1.0, reward_bound=1.0\n",
            "55: loss=1.339, reward_mean=1.0, reward_bound=1.0\n",
            "56: loss=1.313, reward_mean=1.0, reward_bound=1.0\n",
            "57: loss=1.331, reward_mean=1.0, reward_bound=1.0\n",
            "58: loss=1.319, reward_mean=1.0, reward_bound=1.0\n",
            "59: loss=1.316, reward_mean=1.0, reward_bound=1.0\n",
            "60: loss=1.306, reward_mean=1.0, reward_bound=1.0\n",
            "61: loss=1.314, reward_mean=1.0, reward_bound=1.0\n",
            "62: loss=1.309, reward_mean=1.0, reward_bound=1.0\n",
            "63: loss=1.300, reward_mean=1.0, reward_bound=1.0\n",
            "64: loss=1.296, reward_mean=1.0, reward_bound=1.0\n",
            "65: loss=1.309, reward_mean=1.0, reward_bound=1.0\n",
            "66: loss=1.263, reward_mean=1.0, reward_bound=1.0\n",
            "67: loss=1.294, reward_mean=1.0, reward_bound=1.0\n",
            "68: loss=1.276, reward_mean=1.0, reward_bound=1.0\n",
            "69: loss=1.246, reward_mean=1.0, reward_bound=1.0\n",
            "70: loss=1.238, reward_mean=1.0, reward_bound=1.0\n",
            "71: loss=1.244, reward_mean=1.0, reward_bound=1.0\n",
            "72: loss=1.211, reward_mean=1.0, reward_bound=1.0\n",
            "73: loss=1.235, reward_mean=1.0, reward_bound=1.0\n",
            "74: loss=1.185, reward_mean=1.0, reward_bound=1.0\n",
            "75: loss=1.104, reward_mean=1.0, reward_bound=1.0\n",
            "76: loss=1.197, reward_mean=1.0, reward_bound=1.0\n",
            "77: loss=1.129, reward_mean=1.0, reward_bound=1.0\n",
            "78: loss=1.142, reward_mean=1.0, reward_bound=1.0\n",
            "79: loss=1.146, reward_mean=1.0, reward_bound=1.0\n",
            "80: loss=1.023, reward_mean=1.0, reward_bound=1.0\n",
            "81: loss=1.137, reward_mean=1.0, reward_bound=1.0\n",
            "82: loss=1.055, reward_mean=1.0, reward_bound=1.0\n",
            "83: loss=1.157, reward_mean=1.0, reward_bound=1.0\n",
            "84: loss=1.109, reward_mean=1.0, reward_bound=1.0\n",
            "85: loss=1.144, reward_mean=1.0, reward_bound=1.0\n",
            "86: loss=1.113, reward_mean=1.0, reward_bound=1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-378658d0c175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"-cartpole\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0miter_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mobs_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPERCENTILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-8636f4a7df1b>\u001b[0m in \u001b[0;36miterate_batches\u001b[0;34m(env, net, batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mobs_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mact_probs_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mact_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact_probs_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-8bdaef70c462>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     \u001b[0mtens_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhUiN3jRmops"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa_lZmiHx_5y",
        "outputId": "a0c8e2c9-1a3e-41c2-d099-8b5efe581353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'__main__'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7fEvO2-yBJD",
        "outputId": "1ce87876-5486-4b14-8858-47ff06ee0f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "state"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-202074563d3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3YiANFr3csf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}